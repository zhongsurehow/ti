"""
æ•°æ®å¤„ç†å’Œç¼“å­˜ä¼˜åŒ–å·¥å…·
æä¾›é«˜æ•ˆçš„æ•°æ®ç¼“å­˜å’Œå¤„ç†æœºåˆ¶
"""

import pickle
import hashlib
import os
import time
import logging
from datetime import datetime, timedelta
from typing import Any, Dict, Optional, Callable, Union
from pathlib import Path
import streamlit as st
import pandas as pd
import numpy as np

logger = logging.getLogger(__name__)

class PersistentCache:
    """æŒä¹…åŒ–ç¼“å­˜ç±»"""

    def __init__(self, cache_dir: str = "cache", default_ttl: int = 3600):
        self.cache_dir = Path(cache_dir)
        self.cache_dir.mkdir(exist_ok=True)
        self.default_ttl = default_ttl

    def _get_cache_path(self, key: str) -> Path:
        """è·å–ç¼“å­˜æ–‡ä»¶è·¯å¾„"""
        # ä½¿ç”¨MD5å“ˆå¸Œé¿å…æ–‡ä»¶åè¿‡é•¿
        key_hash = hashlib.md5(key.encode()).hexdigest()
        return self.cache_dir / f"{key_hash}.cache"

    def _is_expired(self, cache_path: Path, ttl: int) -> bool:
        """æ£€æŸ¥ç¼“å­˜æ˜¯å¦è¿‡æœŸ"""
        if not cache_path.exists():
            return True

        file_time = cache_path.stat().st_mtime
        return time.time() - file_time > ttl

    def get(self, key: str, ttl: Optional[int] = None) -> Optional[Any]:
        """è·å–ç¼“å­˜æ•°æ®"""
        ttl = ttl or self.default_ttl
        cache_path = self._get_cache_path(key)

        if self._is_expired(cache_path, ttl):
            return None

        try:
            with open(cache_path, 'rb') as f:
                return pickle.load(f)
        except Exception as e:
            logger.warning(f"è¯»å–ç¼“å­˜å¤±è´¥: {e}")
            return None

    def set(self, key: str, value: Any) -> None:
        """è®¾ç½®ç¼“å­˜æ•°æ®"""
        cache_path = self._get_cache_path(key)

        try:
            with open(cache_path, 'wb') as f:
                pickle.dump(value, f)
        except Exception as e:
            logger.error(f"å†™å…¥ç¼“å­˜å¤±è´¥: {e}")

    def delete(self, key: str) -> None:
        """åˆ é™¤ç¼“å­˜"""
        cache_path = self._get_cache_path(key)
        if cache_path.exists():
            cache_path.unlink()

    def clear(self) -> None:
        """æ¸…ç©ºæ‰€æœ‰ç¼“å­˜"""
        for cache_file in self.cache_dir.glob("*.cache"):
            cache_file.unlink()

    def get_cache_info(self) -> Dict[str, Any]:
        """è·å–ç¼“å­˜ä¿¡æ¯"""
        cache_files = list(self.cache_dir.glob("*.cache"))
        total_size = sum(f.stat().st_size for f in cache_files)

        return {
            'file_count': len(cache_files),
            'total_size_mb': total_size / (1024 * 1024),
            'cache_dir': str(self.cache_dir)
        }

class SessionDataManager:
    """ä¼šè¯æ•°æ®ç®¡ç†å™¨"""

    @staticmethod
    def get_or_generate(key: str, generator: Callable, *args, **kwargs) -> Any:
        """ä»session stateè·å–æ•°æ®ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™ç”Ÿæˆ"""
        if key not in st.session_state:
            st.session_state[key] = generator(*args, **kwargs)
        return st.session_state[key]

    @staticmethod
    def invalidate(key: str) -> None:
        """ä½¿session stateä¸­çš„æ•°æ®å¤±æ•ˆ"""
        if key in st.session_state:
            del st.session_state[key]

    @staticmethod
    def get_memory_usage() -> Dict[str, Any]:
        """è·å–session stateå†…å­˜ä½¿ç”¨æƒ…å†µ"""
        total_items = len(st.session_state)

        # ä¼°ç®—å†…å­˜ä½¿ç”¨ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰
        estimated_size = 0
        for key, value in st.session_state.items():
            if isinstance(value, (pd.DataFrame, np.ndarray)):
                estimated_size += value.nbytes if hasattr(value, 'nbytes') else 1000
            elif isinstance(value, (list, dict)):
                estimated_size += len(str(value))
            else:
                estimated_size += 100  # åŸºç¡€ä¼°ç®—

        return {
            'total_items': total_items,
            'estimated_size_mb': estimated_size / (1024 * 1024)
        }

class DataProcessor:
    """æ•°æ®å¤„ç†å·¥å…·"""

    @staticmethod
    def optimize_dataframe(df: pd.DataFrame) -> pd.DataFrame:
        """ä¼˜åŒ–DataFrameå†…å­˜ä½¿ç”¨"""
        if df.empty:
            return df

        optimized_df = df.copy()

        # ä¼˜åŒ–æ•°å€¼åˆ—
        for col in optimized_df.select_dtypes(include=['int64']).columns:
            col_min = optimized_df[col].min()
            col_max = optimized_df[col].max()

            if col_min >= -128 and col_max <= 127:
                optimized_df[col] = optimized_df[col].astype('int8')
            elif col_min >= -32768 and col_max <= 32767:
                optimized_df[col] = optimized_df[col].astype('int16')
            elif col_min >= -2147483648 and col_max <= 2147483647:
                optimized_df[col] = optimized_df[col].astype('int32')

        # ä¼˜åŒ–æµ®ç‚¹æ•°åˆ—
        for col in optimized_df.select_dtypes(include=['float64']).columns:
            optimized_df[col] = pd.to_numeric(optimized_df[col], downcast='float')

        # ä¼˜åŒ–å­—ç¬¦ä¸²åˆ—
        for col in optimized_df.select_dtypes(include=['object']).columns:
            if optimized_df[col].nunique() / len(optimized_df) < 0.5:  # å¦‚æœé‡å¤å€¼è¾ƒå¤š
                optimized_df[col] = optimized_df[col].astype('category')

        return optimized_df

    @staticmethod
    def filter_recent_data(df: pd.DataFrame, time_col: str, hours: int = 24) -> pd.DataFrame:
        """è¿‡æ»¤æœ€è¿‘çš„æ•°æ®"""
        if df.empty or time_col not in df.columns:
            return df

        cutoff_time = datetime.now() - timedelta(hours=hours)
        return df[pd.to_datetime(df[time_col]) >= cutoff_time]

    @staticmethod
    def aggregate_data(df: pd.DataFrame, group_cols: list, agg_dict: dict) -> pd.DataFrame:
        """èšåˆæ•°æ®"""
        if df.empty:
            return df

        return df.groupby(group_cols).agg(agg_dict).reset_index()

def cached_function(ttl: int = 3600, use_persistent: bool = False):
    """ç¼“å­˜è£…é¥°å™¨"""
    def decorator(func: Callable):
        def wrapper(*args, **kwargs):
            # ç”Ÿæˆç¼“å­˜é”®
            cache_key = f"{func.__name__}_{hash(str(args) + str(sorted(kwargs.items())))}"

            if use_persistent:
                # ä½¿ç”¨æŒä¹…åŒ–ç¼“å­˜
                cache = PersistentCache()
                cached_result = cache.get(cache_key, ttl)

                if cached_result is not None:
                    return cached_result

                result = func(*args, **kwargs)
                cache.set(cache_key, result)
                return result
            else:
                # ä½¿ç”¨Streamlitç¼“å­˜
                @st.cache_data(ttl=ttl)
                def cached_func(*args, **kwargs):
                    return func(*args, **kwargs)

                return cached_func(*args, **kwargs)

        return wrapper
    return decorator

# å…¨å±€ç¼“å­˜å®ä¾‹
persistent_cache = PersistentCache()

def display_cache_stats():
    """æ˜¾ç¤ºç¼“å­˜ç»Ÿè®¡ä¿¡æ¯"""
    st.subheader("ğŸ“Š ç¼“å­˜ç»Ÿè®¡")

    col1, col2 = st.columns(2)

    with col1:
        st.markdown("**æŒä¹…åŒ–ç¼“å­˜**")
        cache_info = persistent_cache.get_cache_info()
        st.metric("ç¼“å­˜æ–‡ä»¶æ•°", cache_info['file_count'])
        st.metric("ç¼“å­˜å¤§å° (MB)", f"{cache_info['total_size_mb']:.2f}")

        if st.button("æ¸…ç©ºæŒä¹…åŒ–ç¼“å­˜"):
            persistent_cache.clear()
            st.success("æŒä¹…åŒ–ç¼“å­˜å·²æ¸…ç©º")

    with col2:
        st.markdown("**ä¼šè¯ç¼“å­˜**")
        session_info = SessionDataManager.get_memory_usage()
        st.metric("ä¼šè¯é¡¹ç›®æ•°", session_info['total_items'])
        st.metric("ä¼°ç®—å¤§å° (MB)", f"{session_info['estimated_size_mb']:.2f}")

        if st.button("æ¸…ç©ºä¼šè¯ç¼“å­˜"):
            st.session_state.clear()
            st.success("ä¼šè¯ç¼“å­˜å·²æ¸…ç©º")

def optimize_app_performance():
    """åº”ç”¨æ€§èƒ½ä¼˜åŒ–å»ºè®®"""
    st.subheader("âš¡ æ€§èƒ½ä¼˜åŒ–å»ºè®®")

    # æ£€æŸ¥ç¼“å­˜ä½¿ç”¨æƒ…å†µ
    cache_info = persistent_cache.get_cache_info()
    session_info = SessionDataManager.get_memory_usage()

    suggestions = []

    if cache_info['total_size_mb'] > 100:
        suggestions.append("æŒä¹…åŒ–ç¼“å­˜è¿‡å¤§ï¼Œå»ºè®®æ¸…ç†æ—§ç¼“å­˜æ–‡ä»¶")

    if session_info['estimated_size_mb'] > 50:
        suggestions.append("ä¼šè¯æ•°æ®è¿‡å¤šï¼Œå»ºè®®æ¸…ç†ä¸å¿…è¦çš„session state")

    if session_info['total_items'] > 20:
        suggestions.append("ä¼šè¯é¡¹ç›®è¿‡å¤šï¼Œè€ƒè™‘ä½¿ç”¨æ›´é«˜æ•ˆçš„æ•°æ®ç»“æ„")

    if suggestions:
        for suggestion in suggestions:
            st.warning(f"âš ï¸ {suggestion}")
    else:
        st.success("âœ… åº”ç”¨æ€§èƒ½è‰¯å¥½ï¼Œæ— éœ€ä¼˜åŒ–")
